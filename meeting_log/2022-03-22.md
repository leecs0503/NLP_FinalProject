
2022-03-22 논의
===

[논문 1](https://arxiv.org/abs/1505.00468)

목표: 성능이 50%대인 한국어 VQA를 개발

기존 영어 기반 VQA의 acc는 약 55~65사이 (잘 학습된 경우)

->

한국어 기반 vqa는 ACC가 [skt brain](https://github.com/SKTBrain/KVQA)에서 발표한 논문에서는 37%

[강원대학교 논문](https://www.koreascience.or.kr/article/CFKO201832073078783.pdf)에서 번역기 기반으로 번역체 질문 / 답변에 대한 acc가 50%대 였음

->

지금까지 한 일
===
논문 읽기

논문에서는 어떻게 데이터를 수집하고, 어떤 데이터와, 어떤 모델을 가져다 썼을 때 acc가 어떻게 나왔는지만 쓰여 있었음 \
**deeper LSTM Q + norm I가 가장 성능이 좋았다고 함** \
beam search나 attention network를 잘 활용해 보는 것도 하나의 방법일 수 있겠다


논의 내용
===
우리가 해볼 수 있는 것
1. Transfer Learning을 이용해 기존 VQA 데이터셋을 번역기 기반 질의를 만든 데이터로 1차적으로 학습을 하고 skt brain에서 제공하는 데이터셋을 이용해 모델을 tunning하는 방법

    1. 먼저 영어 데이터셋을 전부 번역기를 돌리고(script)
    
    1. 데이터 클랜징을 한번 하고 (UI)

    1. 데이터를 어딘가에 취합을 하고(구글 드라이브 등)
    
    1. 모델을 적당히 짜고
    
    1. 결과를 평가해서 ->1-4, ... , 최대한 모델을 완성 시키고
    
    1. 해당 모델을 Inference server에서 가져다 서빙하고 (<-> 유저단이랑 통신)

2. ~~한국어 모델하고 영어 모델 둘 다 만든 다음에, 한국어 데이터를 번역을 해서 영어 INPUT으로 만들고 영어 모델을 돌리고 영어 대답이 나오는데, \
이거에 대한 한국어 대답하고 한국어 모델을 다이렉트로 돌린 대답하고 비교를 하자.~~

이후 할 일
===

사용할 수 있는 데이터셋 취합

->

dataset_link에다가 아래 형식으로 저장 (아래는 예시) 각자 하나씩 만들어서 모으기 /dataset_link/ ~ 
```
이름, 링크, 파일 이름, 압축 형식
Training annotations 2017 v2.0*, https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip, v2_Annotations_Train_mscoco.zip, zip
...
```

-> \
해당 데이터들을 다운로드 하고 번역기를 돌리고 적절히 저장하는 스크립트 구현

+창수 할 일: 모델쪽, inference 서버쪽 코드 구조 잡기

+승형 할 일: 프론트쪽을 어느정도 사이즈로 할 지 고민하기

이후 모이는 날
===
3월 24일 (목요일) 오후 10시

todo (다음 모임 이후 할 일 예정)
===
해당 데이터들을 적당한 UI로 클랜징 할 수 있는 서버를 구축 (파일 시스템 기반)
